"""
HuntRED¬Æ v2 - Virtuous Circle Celery Task
Tarea que ejecuta el c√≠rculo virtuoso completo
"""

import asyncio
import logging
from typing import Dict, Any, Optional
from datetime import datetime, timedelta
from celery import Task
import json

# Mock Celery decorators for this implementation
def shared_task(bind=False, max_retries=3, default_retry_delay=300):
    def decorator(func):
        func.delay = lambda *args, **kwargs: func(*args, **kwargs)
        func.retry = lambda exc=None, countdown=300: None
        return func
    return decorator

logger = logging.getLogger(__name__)

@shared_task(bind=True, max_retries=3, default_retry_delay=300)
def execute_virtuous_circle_task(self, business_unit_id: Optional[int] = None, 
                                config_override: Optional[Dict[str, Any]] = None):
    """
    TAREA PRINCIPAL DEL C√çRCULO VIRTUOSO
    Ejecuta el ciclo completo de scraping ‚Üí ML ‚Üí propuestas ‚Üí clientes
    """
    try:
        task_id = f"VC_TASK_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        logger.info(f"üîÑ Starting Virtuous Circle Task: {task_id}")
        
        # Configuraci√≥n del ciclo
        default_config = {
            "scraping": {
                "enabled": True,
                "platforms": ["indeed", "occ_mundial", "computrabajo", "monster", "linkedin"],
                "search_terms": [
                    "recursos humanos", "gerente rrhh", "director recursos humanos",
                    "analista nomina", "especialista talento", "recruiter",
                    "hr manager", "people operations", "talent acquisition"
                ],
                "locations": [
                    "Ciudad de M√©xico", "Guadalajara", "Monterrey", 
                    "Puebla", "Tijuana", "Le√≥n", "Quer√©taro"
                ],
                "max_pages_per_platform": 10,
                "rate_limit_delay": 2.0
            },
            "ml_processing": {
                "enabled": True,
                "models": ["genia", "aura", "sentiment", "turnover"],
                "confidence_threshold": 0.75,
                "retraining_threshold": 1000
            },
            "opportunity_detection": {
                "enabled": True,
                "min_score": 0.6,
                "high_value_threshold": 0.8,
                "growth_indicators": [
                    "hiring_surge", "expansion", "new_locations", 
                    "funding_round", "positive_news"
                ]
            },
            "proposal_generation": {
                "enabled": True,
                "auto_send_threshold": 0.9,
                "quality_threshold": 0.8,
                "personalization_level": "high"
            },
            "client_acquisition": {
                "enabled": True,
                "tracking_duration": 30,  # d√≠as
                "follow_up_enabled": True,
                "escalation_enabled": True
            },
            "feedback_collection": {
                "enabled": True,
                "sources": [
                    "client_responses", "engagement_metrics", 
                    "conversion_rates", "quality_scores"
                ]
            }
        }
        
        # Aplicar configuraci√≥n override si existe
        if config_override:
            config = {**default_config, **config_override}
        else:
            config = default_config
        
        # Ejecutar el c√≠rculo virtuoso
        result = asyncio.run(
            _execute_virtuous_circle_async(task_id, business_unit_id, config)
        )
        
        # Programar siguiente ejecuci√≥n
        if result.get("success"):
            next_execution = datetime.now() + timedelta(hours=24)
            logger.info(f"üìÖ Next virtuous circle scheduled for: {next_execution}")
            
            # En implementaci√≥n real, programar la siguiente tarea
            # execute_virtuous_circle_task.apply_async(
            #     args=[business_unit_id, config_override],
            #     eta=next_execution
            # )
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error in virtuous circle task: {e}")
        
        # Retry logic
        if hasattr(self, 'retry') and self.request.retries < self.max_retries:
            logger.info(f"üîÑ Retrying virtuous circle task (attempt {self.request.retries + 1})")
            raise self.retry(exc=e, countdown=300)
        
        return {
            "success": False,
            "error": str(e),
            "task_id": task_id if 'task_id' in locals() else "unknown",
            "timestamp": datetime.now().isoformat()
        }

async def _execute_virtuous_circle_async(task_id: str, business_unit_id: Optional[int], 
                                       config: Dict[str, Any]) -> Dict[str, Any]:
    """Ejecuta el c√≠rculo virtuoso de forma as√≠ncrona"""
    
    start_time = datetime.now()
    
    try:
        # Inicializar resultado
        result = {
            "success": False,
            "task_id": task_id,
            "business_unit_id": business_unit_id,
            "start_time": start_time.isoformat(),
            "config": config,
            "phases": {},
            "metrics": {},
            "errors": []
        }
        
        # FASE 1: SCRAPING MASIVO
        if config["scraping"]["enabled"]:
            logger.info("üï∑Ô∏è Phase 1: Massive Data Scraping")
            
            scraping_result = await _execute_scraping_phase(
                config["scraping"], business_unit_id
            )
            
            result["phases"]["scraping"] = scraping_result
            
            if not scraping_result.get("success"):
                result["errors"].append("Scraping phase failed")
        
        # FASE 2: PROCESAMIENTO ML
        if config["ml_processing"]["enabled"]:
            logger.info("üß† Phase 2: ML Processing")
            
            ml_result = await _execute_ml_processing_phase(
                config["ml_processing"], 
                result["phases"].get("scraping", {})
            )
            
            result["phases"]["ml_processing"] = ml_result
            
            if not ml_result.get("success"):
                result["errors"].append("ML processing phase failed")
        
        # FASE 3: DETECCI√ìN DE OPORTUNIDADES
        if config["opportunity_detection"]["enabled"]:
            logger.info("üéØ Phase 3: Opportunity Detection")
            
            opportunity_result = await _execute_opportunity_detection_phase(
                config["opportunity_detection"],
                result["phases"].get("ml_processing", {})
            )
            
            result["phases"]["opportunity_detection"] = opportunity_result
            
            if not opportunity_result.get("success"):
                result["errors"].append("Opportunity detection phase failed")
        
        # FASE 4: GENERACI√ìN DE PROPUESTAS
        if config["proposal_generation"]["enabled"]:
            logger.info("üìÑ Phase 4: Proposal Generation")
            
            proposal_result = await _execute_proposal_generation_phase(
                config["proposal_generation"],
                result["phases"].get("opportunity_detection", {})
            )
            
            result["phases"]["proposal_generation"] = proposal_result
            
            if not proposal_result.get("success"):
                result["errors"].append("Proposal generation phase failed")
        
        # FASE 5: SEGUIMIENTO DE CLIENTES
        if config["client_acquisition"]["enabled"]:
            logger.info("üíº Phase 5: Client Acquisition")
            
            acquisition_result = await _execute_client_acquisition_phase(
                config["client_acquisition"],
                result["phases"].get("proposal_generation", {})
            )
            
            result["phases"]["client_acquisition"] = acquisition_result
        
        # FASE 6: RECOLECCI√ìN DE FEEDBACK
        if config["feedback_collection"]["enabled"]:
            logger.info("üìä Phase 6: Feedback Collection")
            
            feedback_result = await _execute_feedback_collection_phase(
                config["feedback_collection"],
                result["phases"]
            )
            
            result["phases"]["feedback_collection"] = feedback_result
        
        # FASE 7: MEJORA DE MODELOS
        logger.info("üöÄ Phase 7: Model Improvement")
        
        improvement_result = await _execute_model_improvement_phase(
            result["phases"].get("feedback_collection", {}),
            result["phases"]
        )
        
        result["phases"]["model_improvement"] = improvement_result
        
        # M√âTRICAS FINALES
        result["metrics"] = await _calculate_cycle_metrics(result["phases"])
        result["end_time"] = datetime.now().isoformat()
        result["total_duration"] = (datetime.now() - start_time).total_seconds()
        
        # Determinar √©xito general
        result["success"] = len(result["errors"]) == 0
        
        # Log final
        if result["success"]:
            logger.info(f"‚úÖ Virtuous Circle completed successfully: {task_id}")
            logger.info(f"üìä Metrics: {result['metrics']}")
        else:
            logger.error(f"‚ùå Virtuous Circle completed with errors: {result['errors']}")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Error in virtuous circle execution: {e}")
        
        return {
            "success": False,
            "task_id": task_id,
            "error": str(e),
            "start_time": start_time.isoformat(),
            "end_time": datetime.now().isoformat(),
            "phases": result.get("phases", {}) if 'result' in locals() else {}
        }

async def _execute_scraping_phase(config: Dict[str, Any], 
                                business_unit_id: Optional[int]) -> Dict[str, Any]:
    """Ejecuta la fase de scraping masivo"""
    
    try:
        # Simular scraping de m√∫ltiples plataformas
        platforms = config["platforms"]
        search_terms = config["search_terms"]
        locations = config["locations"]
        
        scraping_results = {
            "success": True,
            "platforms_scraped": len(platforms),
            "search_terms_used": len(search_terms),
            "locations_covered": len(locations),
            "total_jobs_found": 0,
            "total_companies_identified": 0,
            "total_profiles_extracted": 0,
            "platform_details": {}
        }
        
        # Simular resultados por plataforma
        for platform in platforms:
            platform_jobs = 150 + hash(platform) % 200
            platform_companies = 25 + hash(platform) % 50
            platform_profiles = 75 + hash(platform) % 100
            
            scraping_results["platform_details"][platform] = {
                "jobs_found": platform_jobs,
                "companies_identified": platform_companies,
                "profiles_extracted": platform_profiles,
                "success_rate": 0.85 + (hash(platform) % 15) / 100,
                "data_quality": 0.80 + (hash(platform) % 20) / 100
            }
            
            scraping_results["total_jobs_found"] += platform_jobs
            scraping_results["total_companies_identified"] += platform_companies
            scraping_results["total_profiles_extracted"] += platform_profiles
        
        # Simular delay de scraping
        await asyncio.sleep(0.1)
        
        logger.info(f"üìä Scraping completed: {scraping_results['total_jobs_found']} jobs, "
                   f"{scraping_results['total_companies_identified']} companies")
        
        return scraping_results
        
    except Exception as e:
        logger.error(f"‚ùå Error in scraping phase: {e}")
        return {"success": False, "error": str(e)}

async def _execute_ml_processing_phase(config: Dict[str, Any], 
                                     scraping_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ejecuta la fase de procesamiento ML"""
    
    try:
        models = config["models"]
        confidence_threshold = config["confidence_threshold"]
        
        ml_results = {
            "success": True,
            "models_processed": len(models),
            "confidence_threshold": confidence_threshold,
            "accuracy_improvement": 0.07,  # 7% mejora promedio
            "patterns_discovered": 12,
            "insights_generated": 0,
            "model_details": {}
        }
        
        # Simular procesamiento por modelo
        for model in models:
            model_insights = 20 + hash(model) % 30
            
            ml_results["model_details"][model] = {
                "insights_generated": model_insights,
                "accuracy_score": 0.82 + (hash(model) % 15) / 100,
                "confidence_score": 0.85 + (hash(model) % 10) / 100,
                "processing_time": 45 + hash(model) % 60
            }
            
            ml_results["insights_generated"] += model_insights
        
        # Simular delay de procesamiento ML
        await asyncio.sleep(0.1)
        
        logger.info(f"üß† ML Processing completed: {ml_results['insights_generated']} insights, "
                   f"{ml_results['patterns_discovered']} patterns discovered")
        
        return ml_results
        
    except Exception as e:
        logger.error(f"‚ùå Error in ML processing phase: {e}")
        return {"success": False, "error": str(e)}

async def _execute_opportunity_detection_phase(config: Dict[str, Any],
                                             ml_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ejecuta la fase de detecci√≥n de oportunidades"""
    
    try:
        min_score = config["min_score"]
        high_value_threshold = config["high_value_threshold"]
        
        opportunity_results = {
            "success": True,
            "min_score": min_score,
            "high_value_threshold": high_value_threshold,
            "opportunities_detected": 0,
            "high_value_opportunities": 0,
            "medium_value_opportunities": 0,
            "low_value_opportunities": 0,
            "proposal_triggers": 0,
            "opportunity_details": []
        }
        
        # Simular detecci√≥n de oportunidades
        total_insights = ml_data.get("insights_generated", 100)
        opportunities_detected = int(total_insights * 0.3)  # 30% de insights generan oportunidades
        
        opportunity_results["opportunities_detected"] = opportunities_detected
        
        # Clasificar oportunidades
        for i in range(opportunities_detected):
            score = 0.4 + (hash(f"opp_{i}") % 60) / 100  # Score entre 0.4 y 1.0
            
            if score >= high_value_threshold:
                opportunity_results["high_value_opportunities"] += 1
                if score >= 0.9:
                    opportunity_results["proposal_triggers"] += 1
            elif score >= 0.6:
                opportunity_results["medium_value_opportunities"] += 1
                if score >= 0.75:
                    opportunity_results["proposal_triggers"] += 1
            else:
                opportunity_results["low_value_opportunities"] += 1
        
        logger.info(f"üéØ Opportunity Detection completed: {opportunities_detected} opportunities, "
                   f"{opportunity_results['proposal_triggers']} proposal triggers")
        
        return opportunity_results
        
    except Exception as e:
        logger.error(f"‚ùå Error in opportunity detection phase: {e}")
        return {"success": False, "error": str(e)}

async def _execute_proposal_generation_phase(config: Dict[str, Any],
                                           opportunity_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ejecuta la fase de generaci√≥n de propuestas"""
    
    try:
        auto_send_threshold = config["auto_send_threshold"]
        quality_threshold = config["quality_threshold"]
        
        proposal_results = {
            "success": True,
            "auto_send_threshold": auto_send_threshold,
            "quality_threshold": quality_threshold,
            "proposals_generated": 0,
            "proposals_sent": 0,
            "high_value_proposals": 0,
            "medium_value_proposals": 0,
            "total_proposal_value": 0,
            "proposal_details": []
        }
        
        # Generar propuestas basadas en triggers
        proposal_triggers = opportunity_data.get("proposal_triggers", 0)
        high_value_opps = opportunity_data.get("high_value_opportunities", 0)
        medium_value_opps = opportunity_data.get("medium_value_opportunities", 0)
        
        # Propuestas de alto valor
        high_value_proposals = min(high_value_opps, proposal_triggers)
        proposal_results["high_value_proposals"] = high_value_proposals
        
        # Propuestas de valor medio
        medium_value_proposals = min(medium_value_opps, proposal_triggers - high_value_proposals)
        proposal_results["medium_value_proposals"] = medium_value_proposals
        
        total_proposals = high_value_proposals + medium_value_proposals
        proposal_results["proposals_generated"] = total_proposals
        
        # Simular env√≠o autom√°tico
        auto_sent = int(total_proposals * 0.6)  # 60% se env√≠an autom√°ticamente
        proposal_results["proposals_sent"] = auto_sent
        
        # Simular valor total de propuestas
        avg_proposal_value = 75000  # $75,000 MXN promedio
        proposal_results["total_proposal_value"] = total_proposals * avg_proposal_value
        
        logger.info(f"üìÑ Proposal Generation completed: {total_proposals} proposals generated, "
                   f"{auto_sent} sent automatically")
        
        return proposal_results
        
    except Exception as e:
        logger.error(f"‚ùå Error in proposal generation phase: {e}")
        return {"success": False, "error": str(e)}

async def _execute_client_acquisition_phase(config: Dict[str, Any],
                                          proposal_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ejecuta la fase de adquisici√≥n de clientes"""
    
    try:
        tracking_duration = config["tracking_duration"]
        
        acquisition_results = {
            "success": True,
            "tracking_duration": tracking_duration,
            "proposals_tracked": proposal_data.get("proposals_sent", 0),
            "responses_received": 0,
            "proposals_accepted": 0,
            "new_clients_acquired": 0,
            "conversion_rate": 0.0,
            "revenue_generated": 0,
            "average_deal_size": 0
        }
        
        proposals_sent = proposal_data.get("proposals_sent", 0)
        
        if proposals_sent > 0:
            # Simular tasas de conversi√≥n
            conversion_rate = 0.16  # 16% conversi√≥n promedio
            proposals_accepted = int(proposals_sent * conversion_rate)
            
            acquisition_results["proposals_accepted"] = proposals_accepted
            acquisition_results["new_clients_acquired"] = proposals_accepted
            acquisition_results["conversion_rate"] = conversion_rate
            
            # Simular revenue
            avg_deal_size = 75000  # $75,000 MXN promedio
            revenue_generated = proposals_accepted * avg_deal_size
            
            acquisition_results["revenue_generated"] = revenue_generated
            acquisition_results["average_deal_size"] = avg_deal_size
            
            # Simular respuestas recibidas (m√°s que aceptadas)
            acquisition_results["responses_received"] = int(proposals_sent * 0.4)  # 40% responde
        
        logger.info(f"üíº Client Acquisition: {acquisition_results['new_clients_acquired']} new clients, "
                   f"${acquisition_results['revenue_generated']:,} MXN revenue")
        
        return acquisition_results
        
    except Exception as e:
        logger.error(f"‚ùå Error in client acquisition phase: {e}")
        return {"success": False, "error": str(e)}

async def _execute_feedback_collection_phase(config: Dict[str, Any],
                                           all_phases: Dict[str, Any]) -> Dict[str, Any]:
    """Ejecuta la fase de recolecci√≥n de feedback"""
    
    try:
        sources = config["sources"]
        
        feedback_results = {
            "success": True,
            "sources_analyzed": len(sources),
            "feedback_items_collected": 0,
            "quality_scores": {},
            "improvement_suggestions": [],
            "performance_metrics": {},
            "source_details": {}
        }
        
        # Simular recolecci√≥n de feedback por fuente
        for source in sources:
            feedback_count = 15 + hash(source) % 20
            quality_score = 0.75 + (hash(source) % 25) / 100
            
            feedback_results["source_details"][source] = {
                "feedback_count": feedback_count,
                "quality_score": quality_score,
                "suggestions": [f"Improve {source} accuracy", f"Optimize {source} timing"]
            }
            
            feedback_results["feedback_items_collected"] += feedback_count
            feedback_results["quality_scores"][source] = quality_score
        
        # Generar sugerencias de mejora
        feedback_results["improvement_suggestions"] = [
            "Optimize scraping selectors for better data extraction",
            "Increase ML model training frequency",
            "Improve proposal personalization algorithms",
            "Enhance follow-up sequences for better conversion"
        ]
        
        logger.info(f"üìä Feedback Collection completed: {feedback_results['feedback_items_collected']} items collected")
        
        return feedback_results
        
    except Exception as e:
        logger.error(f"‚ùå Error in feedback collection phase: {e}")
        return {"success": False, "error": str(e)}

async def _execute_model_improvement_phase(feedback_data: Dict[str, Any],
                                         all_phases: Dict[str, Any]) -> Dict[str, Any]:
    """Ejecuta la fase de mejora de modelos"""
    
    try:
        improvement_results = {
            "success": True,
            "improvements_applied": 0,
            "scraping_improvements": 0,
            "ml_improvements": 0,
            "proposal_improvements": 0,
            "process_improvements": 0,
            "improvement_details": []
        }
        
        # Simular aplicaci√≥n de mejoras
        suggestions = feedback_data.get("improvement_suggestions", [])
        
        for suggestion in suggestions:
            if "scraping" in suggestion.lower():
                improvement_results["scraping_improvements"] += 1
            elif "ml" in suggestion.lower() or "model" in suggestion.lower():
                improvement_results["ml_improvements"] += 1
            elif "proposal" in suggestion.lower():
                improvement_results["proposal_improvements"] += 1
            else:
                improvement_results["process_improvements"] += 1
        
        improvement_results["improvements_applied"] = len(suggestions)
        
        # Simular detalles de mejoras
        improvement_results["improvement_details"] = [
            {"type": "scraping", "description": "Updated selectors for better extraction"},
            {"type": "ml", "description": "Retrained models with new data"},
            {"type": "proposal", "description": "Enhanced personalization algorithms"}
        ]
        
        logger.info(f"üöÄ Model Improvement completed: {improvement_results['improvements_applied']} improvements applied")
        
        return improvement_results
        
    except Exception as e:
        logger.error(f"‚ùå Error in model improvement phase: {e}")
        return {"success": False, "error": str(e)}

async def _calculate_cycle_metrics(phases: Dict[str, Any]) -> Dict[str, Any]:
    """Calcula m√©tricas finales del ciclo"""
    
    try:
        # Extraer datos de cada fase
        scraping = phases.get("scraping", {})
        ml_processing = phases.get("ml_processing", {})
        opportunities = phases.get("opportunity_detection", {})
        proposals = phases.get("proposal_generation", {})
        acquisition = phases.get("client_acquisition", {})
        feedback = phases.get("feedback_collection", {})
        improvement = phases.get("model_improvement", {})
        
        metrics = {
            # M√©tricas de scraping
            "total_jobs_scraped": scraping.get("total_jobs_found", 0),
            "total_companies_identified": scraping.get("total_companies_identified", 0),
            "total_profiles_extracted": scraping.get("total_profiles_extracted", 0),
            
            # M√©tricas de ML
            "ml_insights_generated": ml_processing.get("insights_generated", 0),
            "ml_accuracy_improvement": ml_processing.get("accuracy_improvement", 0),
            "patterns_discovered": ml_processing.get("patterns_discovered", 0),
            
            # M√©tricas de oportunidades
            "opportunities_detected": opportunities.get("opportunities_detected", 0),
            "high_value_opportunities": opportunities.get("high_value_opportunities", 0),
            "proposal_triggers": opportunities.get("proposal_triggers", 0),
            
            # M√©tricas de propuestas
            "proposals_generated": proposals.get("proposals_generated", 0),
            "proposals_sent": proposals.get("proposals_sent", 0),
            "total_proposal_value": proposals.get("total_proposal_value", 0),
            
            # M√©tricas de adquisici√≥n
            "new_clients_acquired": acquisition.get("new_clients_acquired", 0),
            "conversion_rate": acquisition.get("conversion_rate", 0),
            "revenue_generated": acquisition.get("revenue_generated", 0),
            
            # M√©tricas de mejora
            "feedback_items_collected": feedback.get("feedback_items_collected", 0),
            "improvements_applied": improvement.get("improvements_applied", 0),
            
            # M√©tricas calculadas
            "circle_efficiency": 0.0,
            "roi_improvement": 0.0,
            "data_quality_score": 0.0
        }
        
        # Calcular m√©tricas derivadas
        if metrics["total_companies_identified"] > 0:
            metrics["opportunity_rate"] = metrics["opportunities_detected"] / metrics["total_companies_identified"]
        else:
            metrics["opportunity_rate"] = 0.0
        
        if metrics["proposals_sent"] > 0:
            metrics["proposal_efficiency"] = metrics["new_clients_acquired"] / metrics["proposals_sent"]
        else:
            metrics["proposal_efficiency"] = 0.0
        
        # Circle efficiency (promedio de varios factores)
        efficiency_factors = [
            min(metrics["total_jobs_scraped"] / 1000, 1.0),  # Scraping efficiency
            ml_processing.get("accuracy_improvement", 0) * 10,  # ML efficiency
            metrics["opportunity_rate"],  # Opportunity efficiency
            metrics["conversion_rate"]  # Conversion efficiency
        ]
        
        metrics["circle_efficiency"] = sum(efficiency_factors) / len(efficiency_factors)
        
        # ROI improvement (simulado)
        metrics["roi_improvement"] = 1.0 + (metrics["circle_efficiency"] * 0.5)
        
        # Data quality score (promedio de calidad de fuentes)
        quality_scores = []
        for platform_data in scraping.get("platform_details", {}).values():
            if isinstance(platform_data, dict) and "data_quality" in platform_data:
                quality_scores.append(platform_data["data_quality"])
        
        if quality_scores:
            metrics["data_quality_score"] = sum(quality_scores) / len(quality_scores)
        else:
            metrics["data_quality_score"] = 0.85  # Default quality score
        
        return metrics
        
    except Exception as e:
        logger.error(f"‚ùå Error calculating cycle metrics: {e}")
        return {"error": str(e)}

# Tareas de soporte para el c√≠rculo virtuoso

@shared_task(bind=True, max_retries=2, default_retry_delay=60)
def schedule_daily_virtuous_circle(self, business_unit_id: Optional[int] = None):
    """Programa la ejecuci√≥n diaria del c√≠rculo virtuoso"""
    
    try:
        logger.info("üìÖ Scheduling daily virtuous circle execution")
        
        # Programar para ejecutar en 1 hora
        execution_time = datetime.now() + timedelta(hours=1)
        
        # En implementaci√≥n real, usar apply_async
        # execute_virtuous_circle_task.apply_async(
        #     args=[business_unit_id],
        #     eta=execution_time
        # )
        
        logger.info(f"‚úÖ Daily virtuous circle scheduled for {execution_time}")
        
        return {
            "success": True,
            "scheduled_time": execution_time.isoformat(),
            "business_unit_id": business_unit_id
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error scheduling daily virtuous circle: {e}")
        return {"success": False, "error": str(e)}

@shared_task(bind=True, max_retries=2, default_retry_delay=60)
def monitor_virtuous_circle_health(self):
    """Monitorea la salud del c√≠rculo virtuoso"""
    
    try:
        logger.info("üîç Monitoring virtuous circle health")
        
        # Simular m√©tricas de salud
        health_metrics = {
            "system_uptime": 99.8,
            "scraping_success_rate": 94.5,
            "ml_accuracy": 87.2,
            "proposal_quality": 83.7,
            "conversion_rate": 16.3,
            "overall_health": "healthy"
        }
        
        # Determinar estado de salud
        if health_metrics["scraping_success_rate"] < 90:
            health_metrics["overall_health"] = "warning"
        
        if health_metrics["ml_accuracy"] < 80:
            health_metrics["overall_health"] = "critical"
        
        logger.info(f"‚úÖ Health check completed: {health_metrics['overall_health']}")
        
        return {
            "success": True,
            "health_metrics": health_metrics,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error monitoring virtuous circle health: {e}")
        return {"success": False, "error": str(e)}

@shared_task(bind=True, max_retries=2, default_retry_delay=60)
def generate_virtuous_circle_report(self, period: str = "daily"):
    """Genera reporte del c√≠rculo virtuoso"""
    
    try:
        logger.info(f"üìä Generating virtuous circle report for {period}")
        
        # Simular datos del reporte
        report_data = {
            "period": period,
            "generated_at": datetime.now().isoformat(),
            "summary": {
                "total_cycles": 7 if period == "weekly" else 1,
                "total_jobs_scraped": 14000 if period == "weekly" else 2000,
                "total_opportunities": 700 if period == "weekly" else 100,
                "total_proposals": 175 if period == "weekly" else 25,
                "total_clients": 28 if period == "weekly" else 4,
                "total_revenue": 2100000 if period == "weekly" else 300000
            },
            "performance": {
                "avg_conversion_rate": 16.0,
                "avg_circle_efficiency": 0.87,
                "avg_data_quality": 0.89,
                "trend": "improving"
            },
            "recommendations": [
                "Continue current optimization strategies",
                "Expand to additional job boards",
                "Increase proposal personalization",
                "Implement advanced ML models"
            ]
        }
        
        logger.info(f"‚úÖ Report generated: {report_data['summary']['total_clients']} clients acquired")
        
        return {
            "success": True,
            "report": report_data
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error generating virtuous circle report: {e}")
        return {"success": False, "error": str(e)}