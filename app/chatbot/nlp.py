# ðŸ“Œ UbicaciÃ³n en servidor: /home/pablo/app/chatbot/nlp.py

import spacy
import json
import logging
from typing import List, Dict, Set, Optional
from transformers import pipeline
from spacy.matcher import PhraseMatcher
from cachetools import cachedmethod, TTLCache
from app.chatbot.utils import clean_text
from tabiya_livelihoods_classifier.inference.linker import EntityLinker

logger = logging.getLogger(__name__)

# Diccionario de modelos por idioma
MODEL_LANGUAGES = {
    "es": "es_core_news_md",  # EspaÃ±ol (LATAM y EspaÃ±a)
    "en": "en_core_web_md",   # InglÃ©s (migrantes y global)
    "pt": "pt_core_news_md",  # PortuguÃ©s (Brasil y migrantes)
    "fr": "fr_core_news_md",  # FrancÃ©s (HaitÃ­ y migrantes)
    "nah": None,              # NÃ¡huatl (sin modelo spaCy, usaremos multilingÃ¼e)
    "yua": None,              # Maya yucateco (sin modelo spaCy, usaremos multilingÃ¼e)
    "default": "xx_ent_wiki_sm"  # Modelo multilingÃ¼e bÃ¡sico de spaCy
}

# Modelos NER por idioma (Hugging Face)
NER_MODELS = {
    "es": "dccuchile/bert-base-spanish-wwm-cased",  # EspaÃ±ol
    "en": "jjzha/jobbert_skill_extraction",         # InglÃ©s
    "pt": "neuralmind/bert-base-portuguese-cased",  # PortuguÃ©s
    "fr": "camembert-base",                         # FrancÃ©s
    "default": "xlm-roberta-base"                   # MultilingÃ¼e (nÃ¡huatl, maya, etc.)
}

# Ruta al catÃ¡logo de habilidades
SKILLS_JSON_PATH = "/home/pablo/app/utilidades/catalogs/skills.json"

def load_skills_catalog() -> Dict:
    """Carga el catÃ¡logo de habilidades desde skills.json."""
    try:
        with open(SKILLS_JSON_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Error cargando skills.json: {e}")
        return {}

class BaseNLPProcessor:
    """Clase base para procesadores NLP que comparten funcionalidades comunes."""
    def __init__(self, language: str = 'es'):
        self.language = language
        self.skills_catalog = load_skills_catalog()
        self._load_nlp_model()
        self._load_ner_pipeline()
        self.sentiment_pipeline = pipeline('sentiment-analysis', 
                                         model='cardiffnlp/twitter-roberta-base-sentiment-latest')
        self.skill_cache = TTLCache(maxsize=5000, ttl=7200)  # Cache de 2 horas

    def _load_nlp_model(self):
        """Carga el modelo spaCy segÃºn el idioma."""
        model = MODEL_LANGUAGES.get(self.language, MODEL_LANGUAGES["default"])
        try:
            self.nlp = spacy.load(model) if model else spacy.load(MODEL_LANGUAGES["default"])
        except Exception as e:
            logger.warning(f"Modelo {model} no disponible para {self.language}: {e}. Usando modelo multilingÃ¼e.")
            self.nlp = spacy.load(MODEL_LANGUAGES["default"])

    def _load_ner_pipeline(self):
        """Carga el pipeline NER segÃºn el idioma."""
        ner_model = NER_MODELS.get(self.language, NER_MODELS["default"])
        try:
            self.ner_pipeline = pipeline('ner', model=ner_model, aggregation_strategy='simple')
        except Exception as e:
            logger.error(f"Error cargando NER para {self.language}: {e}. Usando xlm-roberta-base.")
            self.ner_pipeline = pipeline('ner', model=NER_MODELS["default"], aggregation_strategy='simple')

    def extract_entities(self, text: str) -> List[str]:
        """Extrae entidades nombradas del texto usando spaCy y NER especializado."""
        text = clean_text(text)
        doc = self.nlp(text.lower())
        entities = set()
        
        ner_results = self.ner_pipeline(text)
        for ent in ner_results:
            entities.add(ent['word'].replace('##', '').lower())
        
        for ent in doc.ents:
            entities.add(ent.text.lower())
        return list(entities)

    def get_sentiment(self, text: str) -> str:
        """Analiza el sentimiento del texto usando RoBERTa."""
        try:
            result = self.sentiment_pipeline(text[:512])  # Limite de 512 tokens
            return result[0]['label']
        except Exception as e:
            logger.error(f"Error en anÃ¡lisis de sentimiento: {e}")
            return "neutral"

class CandidateNLPProcessor(BaseNLPProcessor):
    """Procesador NLP para analizar datos de candidatos."""
    def __init__(self, language: str = 'es'):
        super().__init__(language)
        self.matcher = self._build_matcher()
        try:
            self.linkedin_pipeline = pipeline('ner', model='algiraldohe/lm-ner-linkedin-skills-recognition')
        except Exception as e:
            logger.warning(f"Error cargando LinkedIn NER: {e}. Usando NER por defecto.")
            self.linkedin_pipeline = self.ner_pipeline
        
        if language == 'en':
            self.skillner_pipeline = pipeline('ner', model='ihk/skillner')
        else:
            self.skillner_pipeline = None

    def _build_matcher(self) -> PhraseMatcher:
        """Construye un matcher de spaCy con habilidades del catÃ¡logo."""
        matcher = PhraseMatcher(self.nlp.vocab, attr='LOWER')
        skills = set()
        for division in self.skills_catalog.values():
            for role_category in division.values():
                for role, details in role_category.items():
                    for category in ["Habilidades TÃ©cnicas", "Habilidades Blandas", "Certificaciones", "Herramientas"]:
                        skills.update(details.get(category, []))
        patterns = [self.nlp.make_doc(skill.lower()) for skill in skills]
        matcher.add("SKILL", patterns)
        return matcher

    @cachedmethod(lambda self: self.skill_cache)
    def extract_skills(self, text: str) -> Dict[str, List[str]]:
        """Extrae habilidades del texto y las clasifica segÃºn el catÃ¡logo."""
        text = clean_text(text)
        doc = self.nlp(text.lower())
        skills = {"technical": [], "soft": [], "certifications": [], "tools": []}

        # 1. LinkedIn NER
        linkedin_results = self.linkedin_pipeline(text)
        for ent in linkedin_results:
            skill = ent['word'].replace('##', '').lower()
            self._classify_skill(skill, skills)

        # 2. NER especializado
        ner_results = self.ner_pipeline(text)
        for ent in ner_results:
            skill = ent['word'].replace('##', '').lower()
            self._classify_skill(skill, skills)

        # 3. SkillNER (solo inglÃ©s)
        if self.language == 'en' and self.skillner_pipeline:
            skillner_results = self.skillner_pipeline(text)
            for ent in skillner_results:
                skill = ent['word'].replace('##', '').lower()
                self._classify_skill(skill, skills)

        # 4. PhraseMatcher
        matches = self.matcher(doc)
        for _, start, end in matches:
            skill = doc[start:end].text.lower()
            self._classify_skill(skill, skills)

        return skills

    def _classify_skill(self, skill: str, skills_dict: Dict[str, List[str]]):
        """Clasifica una habilidad segÃºn el catÃ¡logo."""
        for division in self.skills_catalog.values():
            for role_category in division.values():
                for role, details in role_category.items():
                    if skill in [s.lower() for s in details.get("Habilidades TÃ©cnicas", [])]:
                        skills_dict["technical"].append(skill)
                    elif skill in [s.lower() for s in details.get("Habilidades Blandas", [])]:
                        skills_dict["soft"].append(skill)
                    elif skill in [s.lower() for s in details.get("Certificaciones", [])]:
                        skills_dict["certifications"].append(skill)
                    elif skill in [s.lower() for s in details.get("Herramientas", [])]:
                        skills_dict["tools"].append(skill)

    def analyze_candidate(self, text: str) -> Dict[str, any]:
        """Analiza el texto de un candidato."""
        skills_data = self.extract_skills(text)
        sentiment = self.get_sentiment(text)
        return {
            "skills": skills_data,
            "sentiment": sentiment
        }

class OpportunityNLPProcessor(BaseNLPProcessor):
    """Procesador NLP para analizar oportunidades laborales."""
    def __init__(self, language: str = 'es'):
        super().__init__(language)
        self.tabiya_linker = EntityLinker()
        if language == 'en':
            self.skillner_pipeline = pipeline('ner', model='ihk/skillner')
        else:
            self.skillner_pipeline = None

    def extract_opportunity_details(self, text: str) -> Dict[str, any]:
        """Extrae detalles clave de una oportunidad laboral."""
        text = clean_text(text)
        entities = self.extract_entities(text)
        details = {"skills": {"technical": [], "soft": []}, "location": None, "contract_type": None, "role": None}

        # ExtracciÃ³n de habilidades con SkillNER (solo inglÃ©s)
        if self.language == 'en' and self.skillner_pipeline:
            skillner_results = self.skillner_pipeline(text)
            for ent in skillner_results:
                skill = ent['word'].replace('##', '').lower()
                self._classify_skill(skill, details["skills"])

        # NER y entidades de spaCy
        for ent in entities:
            if ent in ["mÃ©xico", "sÃ£o paulo", "brasil"]:  # Ejemplo, ampliar con opportunity_db
                details["location"] = ent
            elif ent in ["permanente", "temporal", "freelance"]:
                details["contract_type"] = ent
            else:
                self._classify_skill(ent, details["skills"])

        # IdentificaciÃ³n del rol
        details["role"] = self._identify_role(text)
        return details

    def _classify_skill(self, skill: str, skills_dict: Dict[str, List[str]]):
        """Clasifica habilidades para oportunidades."""
        for division in self.skills_catalog.values():
            for role_category in division.values():
                for role, details in role_category.items():
                    if skill in [s.lower() for s in details.get("Habilidades TÃ©cnicas", [])]:
                        skills_dict["technical"].append(skill)
                    elif skill in [s.lower() for s in details.get("Habilidades Blandas", [])]:
                        skills_dict["soft"].append(skill)

    def _identify_role(self, text: str) -> Optional[str]:
        """Identifica el rol basado en el catÃ¡logo."""
        text_lower = text.lower()
        for division in self.skills_catalog.values():
            for role_category in division.values():
                for role in role_category.keys():
                    if role.lower() in text_lower:
                        return role
        return None

    def classify_job(self, text: str) -> Dict[str, any]:
        """Clasifica el tipo de empleo usando Tabiya."""
        try:
            return self.tabiya_linker.link_text(text)
        except Exception as e:
            logger.error(f"Error en clasificaciÃ³n con Tabiya: {e}")
            return {"classification": "unknown"}

    def analyze_opportunity(self, text: str) -> Dict[str, any]:
        """Analiza una oportunidad laboral completa."""
        details = self.extract_opportunity_details(text)
        job_classification = self.classify_job(text)
        sentiment = self.get_sentiment(text)
        return {
            "details": details,
            "job_classification": job_classification,
            "sentiment": sentiment
        }