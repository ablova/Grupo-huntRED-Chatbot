# /home/pablo/app/ml/analyzers/personality_analyzer.py
"""
Analizador de personalidad que integra datos de diversos assessments.

Este módulo proporciona funcionalidades para analizar la personalidad de los candidatos
basándose en diferentes modelos de evaluación, como el modelo de los Cinco Grandes,
ADN profesional, fit cultural y evaluación de talento.

El módulo se integra con el sistema de ML existente y utiliza caché para optimizar
el rendimiento de las evaluaciones frecuentes.
"""
import json
import logging
import hashlib
from functools import lru_cache
from typing import Dict, Any, Optional, List, Tuple, Union, TypedDict
from datetime import datetime, timedelta

# Django
from django.core.cache import cache
from django.utils import timezone

# Modelos locales
from app.models import BusinessUnit

# Configuración de logging
logger = logging.getLogger(__name__)

# Constantes
DEFAULT_CACHE_TIMEOUT = 3600  # 1 hora en segundos
MAX_CACHE_ENTRIES = 1000  # Máximo número de entradas en caché

# Tipos personalizados
class AnalysisResult(TypedDict, total=False):
    """Estructura de datos para los resultados del análisis."""
    traits: Dict[str, float]
    dimensions: Dict[str, float]
    insights: Dict[str, Any]
    recommendations: List[str]
    timestamp: str
    metadata: Dict[str, Any]

class AssessmentData(TypedDict, total=False):
    """Estructura de datos para la entrada de evaluación."""
    assessment_type: str
    responses: Dict[str, Union[str, int, float]]
    metadata: Dict[str, Any]
    timestamp: str

class PersonalityAnalyzer:
    """
    Analizador de personalidad que integra datos de diversos assessments.
    
    Esta clase proporciona métodos para analizar la personalidad de los candidatos
    utilizando diferentes modelos de evaluación. Soporta múltiples tipos de evaluaciones
    y utiliza caché para optimizar el rendimiento.
    
    Atributos:
        ml_system: Instancia del sistema de aprendizaje automático para análisis avanzado
        cache_timeout: Tiempo de expiración de la caché en segundos (por defecto: 1 hora)
    """
    
    # Definición de rasgos de personalidad para diferentes modelos
    PERSONALITY_TRAITS = {
        'big_five': ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism'],
        'professional_dna': ['strategic_thinking', 'emotional_intelligence', 'adaptability', 
                           'collaboration', 'innovation', 'resilience', 'results_orientation'],
        'leadership': ['vision', 'influence', 'motivation', 'decision_making', 'accountability'],
        'cultural_fit': ['adaptability', 'values_alignment', 'team_orientation', 'growth_mindset', 'work_ethic']
    }
    
    # Umbrales para análisis de fortalezas y debilidades
    STRENGTH_THRESHOLD = 0.7  # 70% o superior se considera fortaleza
    IMPROVEMENT_THRESHOLD = 0.4  # 40% o inferior se considera área de mejora
    
    def __init__(self, ml_system=None, cache_timeout: int = DEFAULT_CACHE_TIMEOUT):
        """
        Inicializa el analizador de personalidad con un sistema de ML opcional.
        
        Args:
            ml_system: Instancia del sistema de ML para análisis avanzado (opcional)
            cache_timeout: Tiempo de expiración de la caché en segundos (opcional)
        """
        self.ml_system = ml_system or MatchmakingLearningSystem()
        self.cache_timeout = cache_timeout
        self.cache_prefix = "personality_analyzer_"
        self._init_cache()
    
    def _init_cache(self) -> None:
        """Inicializa la caché si es necesario."""
        # La caché de Django se inicializa automáticamente
        pass
        
    def _generate_cache_key(self, data: Dict[str, Any]) -> str:
        """
        Genera una clave de caché única para los datos de entrada.
        
        Args:
            data: Datos de entrada para el análisis
                
        Returns:
            str: Clave de caché generada
        """
        data_str = json.dumps(data, sort_keys=True)
        return f"{self.cache_prefix}{hashlib.md5(data_str.encode()).hexdigest()}"
    
    def _get_cached_result(self, cache_key: str) -> Optional[AnalysisResult]:
        """
        Obtiene un resultado de la caché si está disponible.
        
        Args:
            cache_key: Clave de caché para buscar
                
        Returns:
            AnalysisResult or None: Resultado en caché o None si no existe
        """
        return cache.get(cache_key)
    
    def _set_cached_result(self, cache_key: str, result: AnalysisResult, 
                         timeout: int = None) -> None:
        """
        Almacena un resultado en la caché.
        
        Args:
            cache_key: Clave de caché
            result: Resultado a almacenar
            timeout: Tiempo de expiración en segundos (opcional, usa self.cache_timeout por defecto)
        """
        cache.set(cache_key, result, timeout=timeout or self.cache_timeout)
    
    def validate_assessment_data(self, data: AssessmentData) -> bool:
        """
        Valida los datos de evaluación de entrada.
        
        Args:
            data: Datos de evaluación a validar
                
        Returns:
            bool: True si los datos son válidos, False en caso contrario
        """
        required_fields = ['assessment_type', 'responses']
        return all(field in data for field in required_fields)
        
    def analyze(self, candidate_data: Dict[str, Any], 
               business_unit: Optional[BusinessUnit] = None) -> AnalysisResult:
        """
        Analiza la personalidad del candidato basándose en los datos proporcionados.
        
        Args:
            candidate_data: Datos del candidato, incluyendo evaluaciones
            business_unit: Unidad de negocio para la personalización (opcional)
                
        Returns:
            AnalysisResult: Resultados del análisis de personalidad
                
        Raises:
            ValueError: Si los datos de entrada son inválidos
        """
        if not self.validate_assessment_data(candidate_data):
            raise ValueError("Datos de evaluación inválidos o incompletos")
            
        cache_key = self._generate_cache_key(candidate_data)
        cached_result = self._get_cached_result(cache_key)
        
        if cached_result:
            logger.debug("Resultado encontrado en caché")
            return cached_result
            
        try:
            # Procesar los datos de evaluación
            result = self._process_assessment_data(candidate_data, business_unit)
            
            # Almacenar en caché
            self._set_cached_result(cache_key, result)
            
            return result
            
        except Exception as e:
            logger.error(f"Error al analizar la personalidad: {str(e)}")
            raise
        
    def _validate_input_data(self, data: Dict) -> None:
        """
        Valida los datos de entrada del análisis.
        
        Args:
            data: Datos del candidato a validar
            
        Raises:
            ValueError: Si los datos son inválidos o faltan campos requeridos
        """
        if not data or not isinstance(data, dict):
            raise ValueError("Los datos del candidato son inválidos o están vacíos")
            
        # Verificar campos requeridos
        required_fields = ['assessment_type', 'responses']
        for field in required_fields:
            if field not in data:
                raise ValueError(f"Campo requerido faltante: {field}")
        
        # Validar que las respuestas sean un diccionario no vacío
        if not isinstance(data.get('responses'), dict) or not data['responses']:
            raise ValueError("Las respuestas del assessment deben ser un diccionario no vacío")
        
        # Validar tipo de assessment
        valid_assessment_types = ['personality', 'professional_dna', 'cultural_fit', 'talent']
        if data.get('assessment_type') not in valid_assessment_types:
            logger.warning(f"Tipo de assessment no reconocido: {data.get('assessment_type')}")
    
    def _get_cache_key(self, data: Dict) -> str:
        """
        Genera una clave de caché única para los datos del candidato.
        
        Args:
            data: Datos del candidato
            
        Returns:
            str: Clave de caché única
        """
        # Usar solo los campos relevantes para la clave de caché
        cache_data = {
            'assessment_type': data.get('assessment_type'),
            'responses_hash': self._hash_dict(data.get('responses', {})),
            'version': 'v1'  # Versión del esquema de caché
        }
        
        # Convertir a JSON y luego a hash MD5 para una clave consistente
        cache_str = json.dumps(cache_data, sort_keys=True)
        return f"personality_analysis_{hashlib.md5(cache_str.encode('utf-8')).hexdigest()}"
    
    @staticmethod
    def _hash_dict(data: Dict) -> str:
        """
        Genera un hash único para un diccionario.
        
        Args:
            data: Diccionario a hashear
            
        Returns:
            str: Hash MD5 del diccionario serializado
        """
        return hashlib.md5(json.dumps(data, sort_keys=True).encode('utf-8')).hexdigest()
    
    def _process_assessment_data(self, data: Dict, business_unit: Optional[BusinessUnit] = None) -> AnalysisResult:
        """
        Procesa los datos de assessment según su tipo y unidad de negocio.
        
        Args:
            data: Datos del assessment
            business_unit: Unidad de negocio para contextualizar el análisis
            
        Returns:
            AnalysisResult: Resultados del análisis
            
        Raises:
            ValueError: Si el tipo de assessment no es soportado
        """
        assessment_type = data.get('assessment_type', 'personality')
        logger.debug(f"Procesando assessment de tipo: {assessment_type}")
        
        # Mapeo de tipos de assessment a sus respectivos manejadores
        handlers = {
            'personality': self._analyze_personality,
            'professional_dna': self._analyze_professional_dna,
            'cultural_fit': self._analyze_cultural_fit,
            'talent': self._analyze_talent
        }
        
        # Obtener el manejador apropiado o usar el genérico
        handler = handlers.get(assessment_type, self._analyze_generic)
        
        # Ejecutar el análisis
        result = handler(data, business_unit)
        
        # Asegurar que el resultado tenga la estructura correcta
        if not isinstance(result, dict):
            logger.warning(f"El manejador para {assessment_type} no devolvió un diccionario")
            return self._get_default_analysis(assessment_type=assessment_type)
            
        return result
    
    def _analyze_personality(self, data: Dict, business_unit: Optional[BusinessUnit] = None) -> AnalysisResult:
        """
        Analiza datos de personalidad según el modelo de los Cinco Grandes.
        
        Este método implementa el análisis de personalidad basado en el modelo de los
        Cinco Grandes (Big Five), que evalúa cinco dimensiones principales de la personalidad:
        apertura a la experiencia, responsabilidad, extraversión, amabilidad y neuroticismo.
        
        Args:
            data: Datos del assessment de personalidad
            business_unit: Unidad de negocio para contextualizar recomendaciones
            
        Returns:
            AnalysisResult: Resultados del análisis de personalidad
        """
        try:
            # Extraer respuestas relevantes
            responses = data.get('responses', {})
            
            # Validar que hay suficientes respuestas
            if not responses:
                logger.warning("No se encontraron respuestas para el análisis de personalidad")
                return self._get_default_analysis(
                    assessment_type='personality',
                    error_message="No se encontraron respuestas para el análisis"
                )
            
            logger.debug(f"Analizando {len(responses)} respuestas de personalidad")
            
            # Calcular puntuaciones de rasgos
            traits = {}
            for trait in self.PERSONALITY_TRAITS['big_five']:
                trait_score = self._calculate_trait_score(trait, responses)
                traits[trait] = trait_score
                
            # Generar insights basados en puntuaciones
            strengths, improvements = self._identify_strengths_improvements(traits)
            recommended_roles = self._recommend_roles(traits, business_unit)
            
            # Crear resultado estructurado
            result: AnalysisResult = {
                'traits': traits,
                'insights': {
                    'strengths': strengths,
                    'areas_improvement': improvements,
                    'recommended_roles': recommended_roles,
                    'overall_score': sum(traits.values()) / len(traits) if traits else 0.0
                },
                'recommendations': self._generate_personality_recommendations(
                    traits, 
                    strengths, 
                    improvements,
                    business_unit
                )
            }
            
            return result
            
        except Exception as e:
            logger.error(f"Error en el análisis de personalidad: {str(e)}", exc_info=True)
            return self._get_default_analysis(
                assessment_type='personality',
                error_message=str(e)
            )
    
    def _analyze_professional_dna(self, data: Dict, business_unit: Any) -> Dict:
        """Analiza datos específicos de ADN profesional."""
        # Extraer respuestas relevantes
        responses = data.get('responses', {})
        
        # Calcular puntuaciones de dimensiones
        dimensions = {}
        for dimension in self.PERSONALITY_TRAITS['professional_dna']:
            dimension_score = self._calculate_dimension_score(dimension, responses)
            dimensions[dimension] = dimension_score
            
        # Generar insights basados en puntuaciones
        insights = self._generate_professional_dna_insights(dimensions)
        recommendations = self._generate_professional_dna_recommendations(dimensions, business_unit)
        
        return {
            'dimensions': dimensions,
            'insights': insights,
            'recommendations': recommendations
        }
    
    def _analyze_cultural_fit(self, data: Dict, business_unit: Any) -> Dict:
        """Analiza datos de fit cultural."""
        # Implementación básica que se puede expandir
        cultural_aspects = {}
        for aspect in self.PERSONALITY_TRAITS['cultural_fit']:
            cultural_aspects[aspect] = data.get(aspect, 0.5)
            
        return {
            'cultural_fit': cultural_aspects,
            'compatibility_score': sum(cultural_aspects.values()) / len(cultural_aspects),
            'recommendations': [
                'Evaluar alineación con valores de la empresa',
                'Considerar dinámicas de equipo en la entrevista'
            ]
        }
    
    def _analyze_talent(self, data: Dict, business_unit: Any) -> Dict:
        """Analiza datos de evaluación de talento."""
        # Implementación básica
        skill_levels = data.get('skill_levels', {})
        experience = data.get('experience', {})
        
        return {
            'skill_assessment': skill_levels,
            'experience_assessment': experience,
            'talent_score': 0.7,  # Placeholder, se implementaría algoritmo real
            'development_areas': ['Liderazgo técnico', 'Gestión de proyectos']
        }
    
    def _analyze_generic(self, data: Dict, business_unit: Any) -> Dict:
        """Analiza datos genéricos cuando no hay tipo específico."""
        # Fallback genérico
        return {
            'general_score': 0.7,
            'recommendations': [
                'Revisar historial profesional para evaluar trayectoria',
                'Considerar entrevista adicional para validar habilidades'
            ]
        }
        
    def _calculate_trait_score(self, trait: str, responses: Dict) -> float:
        """Calcula la puntuación para un rasgo basado en las respuestas."""
        # Implementación básica que se puede expandir
        trait_questions = [q for q in responses.keys() if trait in q.lower()]
        if not trait_questions:
            return 0.5  # Valor por defecto
            
        scores = [float(responses[q]) for q in trait_questions if responses[q]]
        return sum(scores) / len(scores) if scores else 0.5
        
    def _calculate_dimension_score(self, dimension: str, responses: Dict) -> float:
        """Calcula la puntuación para una dimensión de DNA profesional."""
        # Similar a trait_score pero adaptado a dimensiones profesionales
        dimension_questions = [q for q in responses.keys() if dimension.replace('_', ' ') in q.lower()]
        if not dimension_questions:
            return 50.0  # Valor por defecto (escala 0-100)
            
        scores = []
        for q in dimension_questions:
            if responses[q]:
                # Convertir respuestas a escala 0-100
                try:
                    val = float(responses[q])
                    # Asumiendo respuestas en escala 1-5
                    scores.append((val - 1) * 25)  # Convierte 1-5 a 0-100
                except (ValueError, TypeError):
                    continue
                    
        return sum(scores) / len(scores) if scores else 50.0
        
    def _identify_strengths_improvements(self, traits: Dict) -> Tuple[List[str], List[str]]:
        """Identifica fortalezas y áreas de mejora basadas en rasgos."""
        strengths = []
        improvements = []
        
        # Mapeo de rasgos a fortalezas (alto) y mejoras (bajo)
        trait_mapping = {
            'openness': ('Creatividad e innovación', 'Apertura a nuevas ideas'),
            'conscientiousness': ('Organización y responsabilidad', 'Planificación y disciplina'),
            'extraversion': ('Habilidades sociales y comunicativas', 'Asertividad en grupos'),
            'agreeableness': ('Trabajo en equipo y empatía', 'Colaboración y consenso'),
            'neuroticism': ('Estabilidad emocional', 'Manejo del estrés')
        }
        
        # Umbrales para considerar alto o bajo
        high_threshold = 0.7
        low_threshold = 0.3
        
        for trait, score in traits.items():
            if trait == 'neuroticism':
                # Para neuroticismo, bajo es bueno (estabilidad emocional)
                if score < low_threshold:
                    strengths.append(trait_mapping[trait][0])
                elif score > high_threshold:
                    improvements.append(trait_mapping[trait][1])
            else:
                # Para otros rasgos, alto es generalmente bueno
                if score > high_threshold:
                    strengths.append(trait_mapping[trait][0])
                elif score < low_threshold:
                    improvements.append(trait_mapping[trait][1])
                    
        return strengths, improvements
        
    def _recommend_roles(self, traits: Dict, business_unit: Any) -> List[str]:
        """Recomienda roles basados en perfil de personalidad y BU."""
        # Implementación básica que se puede expandir
        
        # Si no hay BU, dar recomendaciones genéricas
        if not business_unit:
            return ['Analista', 'Especialista', 'Coordinador']
            
        # Mapeo simplificado de rasgos dominantes a roles por BU
        bu_role_mapping = {
            'huntRED': {
                'openness': ['Consultor de Innovación', 'Estratega de Transformación'],
                'conscientiousness': ['Gerente de Proyectos', 'Director de Operaciones'],
                'extraversion': ['Director Comercial', 'Gerente de Relaciones Públicas'],
                'agreeableness': ['Gerente de Recursos Humanos', 'Director de Cultura Organizacional'],
                'low_neuroticism': ['Director General', 'Gerente de Crisis']
            },
            'huntU': {
                'openness': ['Desarrollador Creativo', 'Investigador'],
                'conscientiousness': ['Analista de Datos', 'Ingeniero de Calidad'],
                'extraversion': ['Ejecutivo de Ventas', 'Coordinador de Eventos'],
                'agreeableness': ['Especialista en Atención al Cliente', 'Coordinador de Equipo'],
                'low_neuroticism': ['Analista de Riesgos', 'Coordinador de Proyectos']
            },
            'Amigro': {
                'openness': ['Desarrollador de Soluciones', 'Especialista en Mejora Continua'],
                'conscientiousness': ['Supervisor de Operaciones', 'Administrador de Inventario'],
                'extraversion': ['Representante de Ventas', 'Ejecutivo de Servicio'],
                'agreeableness': ['Representante de Servicio al Cliente', 'Coordinador de Comunidad'],
                'low_neuroticism': ['Supervisor de Logística', 'Coordinador de Campo']
            }
        }
        
        # Determinar rasgo dominante (excluye neuroticismo)
        dominant_traits = []
        for trait, score in traits.items():
            if trait != 'neuroticism' and score > 0.65:
                dominant_traits.append(trait)
                
        if traits.get('neuroticism', 1.0) < 0.35:
            dominant_traits.append('low_neuroticism')
            
        # Si no hay rasgos dominantes, dar recomendación genérica para esa BU
        if not dominant_traits:
            return ['Posición analítica', 'Rol de especialista']
            
        # Obtener roles para los rasgos dominantes
        recommended_roles = []
        bu_name = getattr(business_unit, 'name', str(business_unit))
        bu_name = bu_name if bu_name in bu_role_mapping else 'huntRED'
        
        for trait in dominant_traits:
            if trait in bu_role_mapping[bu_name]:
                recommended_roles.extend(bu_role_mapping[bu_name][trait])
                
        return recommended_roles[:3]  # Limitar a 3 recomendaciones
        
    def _generate_professional_dna_insights(self, dimensions: Dict) -> Dict:
        """Genera insights basados en dimensiones de DNA profesional."""
        insights = {}
        
        # Definir interpretaciones para cada dimensión
        dimension_insights = {
            'strategic_thinking': 'Capacidad para pensar a largo plazo y alinear acciones con objetivos',
            'emotional_intelligence': 'Habilidad para reconocer y gestionar emociones propias y ajenas',
            'adaptability': 'Flexibilidad para ajustarse a cambios y nuevos entornos',
            'collaboration': 'Efectividad trabajando con otros para lograr objetivos comunes',
            'innovation': 'Capacidad para generar y aplicar ideas nuevas',
            'resilience': 'Fortaleza para recuperarse de dificultades y persistir',
            'results_orientation': 'Enfoque en lograr objetivos medibles y tangibles'
        }
        
        # Generar insight para cada dimensión
        for dimension, score in dimensions.items():
            base_insight = dimension_insights.get(dimension, '')
            if score > 75:
                level = "alto"
                impact = "una fortaleza significativa"
            elif score > 50:
                level = "moderado"
                impact = "un área con buen desarrollo"
            else:
                level = "en desarrollo"
                impact = "un área de oportunidad"
                
            insights[dimension] = f"{base_insight}. Tu nivel es {level}, lo que representa {impact}."
            
        return insights
        
    def _generate_professional_dna_recommendations(self, dimensions: Dict, business_unit: Any) -> List[str]:
        """Genera recomendaciones basadas en DNA profesional."""
        recommendations = []
        
        # Identificar dimensiones más bajas (áreas de oportunidad)
        low_dimensions = [d for d, score in dimensions.items() if score < 50]
        
        # Recomendaciones generales basadas en dimensiones bajas
        dimension_recommendations = {
            'strategic_thinking': 'Desarrollar habilidades de pensamiento a largo plazo y planificación',
            'emotional_intelligence': 'Practicar la autoconciencia y la empatía en interacciones profesionales',
            'adaptability': 'Exponerse a situaciones nuevas y diversas para aumentar flexibilidad',
            'collaboration': 'Participar en proyectos de equipo que requieran coordinación efectiva',
            'innovation': 'Dedicar tiempo a la generación de ideas y soluciones creativas',
            'resilience': 'Desarrollar técnicas de manejo del estrés y recuperación',
            'results_orientation': 'Establecer objetivos claros y medibles para tareas y proyectos'
        }
        
        # Añadir recomendaciones para dimensiones bajas
        for dimension in low_dimensions:
            if dimension in dimension_recommendations:
                recommendations.append(dimension_recommendations[dimension])
                
        # Añadir recomendaciones basadas en dimensiones altas (fortalezas)
        high_dimensions = [d for d, score in dimensions.items() if score > 75]
        if high_dimensions:
            high_dim = high_dimensions[0]  # Tomar la primera dimensión alta
            recommendations.append(f"Aprovechar tu alta {high_dim.replace('_', ' ')} en roles que requieran esta habilidad")
            
        # Añadir recomendación general si no hay muchas específicas
        if len(recommendations) < 2:
            recommendations.append("Buscar oportunidades de desarrollo integral en todas las dimensiones del ADN profesional")
            
        return recommendations
        
    def _enrich_with_ml_insights(self, result: Dict, candidate_data: Dict, business_unit: Any) -> Dict:
        """Enriquece los resultados con insights del sistema ML."""
        try:
            # Solo si tenemos suficiente información del candidato
            if 'personality_traits' in candidate_data or 'responses' in candidate_data:
                # Usar el sistema ML existente para obtener insights adicionales
                # Esto podría incluir predicciones basadas en modelos entrenados
                
                # Ejemplo de enriquecimiento:
                result['ml_insights'] = {
                    'market_alignment': 0.75,
                    'success_probability': 0.68,
                    'development_path': [
                        'Especializarse en habilidades técnicas core',
                        'Desarrollar competencias de liderazgo',
                        'Fortalecer habilidades de comunicación escrita'
                    ]
                }
                
                # Si el sistema ML tiene funcionalidad de matchmaking, usarla
                if hasattr(self.ml_system, 'calculate_personality_similarity'):
                    # Simulamos un objeto persona y vacante para la interfaz existente
                    # En una implementación real, construiríamos estos objetos adecuadamente
                    class MockObject:
                        def __init__(self, **kwargs):
                            for key, value in kwargs.items():
                                setattr(self, key, value)
                    
                    person = MockObject(personality_traits=result.get('traits', {}))
                    vacancy = MockObject(culture_fit={})
                    
                    # Calcular similitud usando el sistema existente
                    similarity = 0.5  # Valor por defecto
                    try:
                        similarity = self.ml_system.calculate_personality_similarity(person, vacancy)
                    except Exception as e:
                        logger.warning(f"Error calculating personality similarity: {str(e)}")
                        
                    result['personality_match'] = similarity
                
            return result
        except Exception as e:
            logger.error(f"Error enriching with ML insights: {str(e)}")
            return result  # Devolver el resultado sin enriquecer

    def _get_default_analysis(self) -> Dict:
        """
        Proporciona un análisis por defecto en caso de error.
        
        Returns:
            Dict: Resultado de análisis por defecto
        """
        return {
            'traits': {
                'openness': 0.5,
                'conscientiousness': 0.5,
                'extraversion': 0.5,
                'agreeableness': 0.5,
                'neuroticism': 0.5
            },
            'insights': {
                'note': 'Este es un análisis por defecto debido a un error en el procesamiento.',
                'recommendations': [
                    'Realizar una evaluación completa para obtener resultados precisos',
                    'Proporcionar datos adicionales para mejorar el análisis'
                ]
            }
        }
